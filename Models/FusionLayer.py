import torch
import torch.nn as nn
import torch.nn.functional as F


class FusionFactory:
    @staticmethod
    def create(fusion_type: str, feat_dims: list[int], fusion_dim: int, 
               total_dim: int = None, **kwargs):
        
        """
        ë©€í‹°ëª¨ë‹¬ Fusion ëª¨ë“ˆ íŒ©í† ë¦¬ í•¨ìˆ˜
        
        ëª¨ë“  Fusion ëª¨ë“ˆì„ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            fusion_type (str): Fusion ì¢…ë¥˜
                - "concat": ë‹¨ìˆœ ì—°ê²° MLP [Group 1]
                - "advanced_mlp": ê¹Šì€ MLP + LayerNorm [Group 1] 
                - "modal_gating": Softmax ëª¨ë‹¬ ê°€ì¤‘í•© [Group 2]
                - "sigmoid_modal": Sigmoid ëª¨ë‹¬ ê°€ì¤‘í•© [Group 2]
                - "cross_attention": ëª¨ë‹¬ ê°„ Self-Attention [Group 3]
                - "hypernet": ë™ì  ê°€ì¤‘ì¹˜ ìƒì„± Hypernetwork [Group 2]
                - "moe": Top-k Mixture of Experts [Group 2]
            
            feat_dims (list[int]): ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì¶œë ¥ ì°¨ì› [enc.out_dim for enc in encoders]
                ex) [64, 32, 16] = ì´ë¯¸ì§€64ì°¨ì›, í…ìŠ¤íŠ¸32ì°¨ì›, ì˜¤ë””ì˜¤16ì°¨ì›
            
            fusion_dim (int): ìµœì¢… Fusion ì¶œë ¥ ì°¨ì› (ë³´í†µ 128)
            
            total_dim (int, optional): sum(feat_dims)ì˜ shortcut. ìë™ ê³„ì‚°ë¨
            
            **kwargs: ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°
                - advanced_mlp: dropout=0.1, act_fn=nn.GELU
                - cross_attention: num_heads=8
                - moe: top_k=2
        
        Returns:
            nn.Module: feat_list[list[torch.Tensor]] -> (B, fusion_dim)
            
        Raises:
            ValueError: ì•Œ ìˆ˜ ì—†ëŠ” fusion_type
        
        Examples:
            >>> feat_dims = [64, 32, 16]  # 3ê°œ ëª¨ë‹¬
            >>> fusion = FusionFactory.create("sigmoid_modal", feat_dims, 128)
            >>> feats = [img_feat, txt_feat, audio_feat]  # list of (B, Di)
            >>> fused = fusion(feats)  # (B, 128)
            
            >>> # ì‹¤í—˜í•˜ë©° ì‰½ê²Œ êµì²´
            >>> fusion = FusionFactory.create("cross_attention", feat_dims, 128, num_heads=4)
        
        Notes:
            - Group 1 (total_dim): concat ê¸°ë°˜ MLP ê³„ì—´
            - Group 2 (feat_dims): ëª¨ë‹¬ë³„ ì²˜ë¦¬ ì¸ì‹  
            - Group 3 (feat_dims+total_dim): Attention ê³„ì—´
        """
        
        total_dim = total_dim or sum(feat_dims)
        feat_dims = feat_dims or [total_dim]  # backward compat
        fusion_type = fusion_type.lower()
        if fusion_type not in ["concat", "advanced_mlp", "modal_gating", "sigmoid_modal",
                               "cross_attention", "hypernet", "moe"]:
            raise ValueError(f"Unknown fusion type: {fusion_type}")


        if fusion_type == "concat":
            return ConcatFusion(total_dim, fusion_dim)
        elif fusion_type == "advanced_mlp":
            return AdvancedMLPFusion(total_dim, fusion_dim, **kwargs)
        elif fusion_type == "modal_gating":
            return ModalGatingFusion(feat_dims, fusion_dim)
        elif fusion_type == "sigmoid_modal":
            return SigmoidModalFusion(feat_dims, fusion_dim)
        elif fusion_type == "cross_attention":
            return CrossModalAttention(feat_dims, fusion_dim, total_dim, **kwargs)
        elif fusion_type == "hypernet":
            return HypernetFusion(feat_dims, fusion_dim)
        elif fusion_type == "moe":
            return ModalMoE(feat_dims, fusion_dim, **kwargs)
        else:
            raise ValueError(f"Unknown fusion type: {fusion_type}")




# 2. Fusion ëª¨ë“ˆ
class ConcatFusion(nn.Module):
    def __init__(self, total_dim: int, fusion_dim: int, act_fn=nn.GELU):

        """
        ê¸°ë³¸ Late Fusion: ëª¨ë“  ëª¨ë‹¬ íŠ¹ì§•ì„ ë‹¨ìˆœ ì—°ê²°(concat) í›„ MLP

        Args:
            total_dim (int): ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì„ë² ë”© ì°¨ì›ì„ ì „ë¶€ í•©ì¹œ ê°’
            fusion_dim (int): ìµœì¢… ì°¨ì›
            act_fn (nn.Module): í™œì„±í™” í•¨ìˆ˜
    
        """
        super().__init__()
        self.fusion = nn.Sequential(
            nn.Linear(total_dim, fusion_dim),
            act_fn(),
        )

    def forward(self, feat_list: list[torch.Tensor]) -> torch.Tensor:
        if not feat_list:
            raise ValueError("No features to fuse")
        return self.fusion(torch.cat(feat_list, dim=1))
    
class AdvancedMLPFusion(nn.Module):
    
    def __init__(self, total_dim, fusion_dim, dropout=0.1, act_fn=nn.GELU):
        
        """
        Concat Fusion ê°œì„ íŒ: ê¹Šì€ MLP + LayerNorm + Dropout (2->3ì¸µ)
        ê³¼ì í•© ë°©ì§€ + í‘œí˜„ë ¥ ê°•í™”

        Args:
            total_dim (int): ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì„ë² ë”© ì°¨ì›ì„ ì „ë¶€ í•©ì¹œ ê°’
            fusion_dim (int): ìµœì¢… ì°¨ì›
            dropout (float): Dropout ë¹„ìœ¨
            act_fn (nn.Module): í™œì„±í™” í•¨ìˆ˜
        """

        super().__init__()
        self.fusion = nn.Sequential(
            nn.Linear(total_dim, fusion_dim),
            nn.LayerNorm(fusion_dim),
            act_fn(),
            nn.Dropout(dropout) if dropout > 0 else nn.Identity(),
            nn.Linear(fusion_dim, fusion_dim),
            nn.LayerNorm(fusion_dim),
            act_fn(),
        )
    def forward(self, feat_list: list[torch.Tensor]) -> torch.Tensor:
        if not feat_list:
            raise ValueError("No features to fuse")
        return self.fusion(torch.cat(feat_list, dim=1))


class ModalGatingFusion(nn.Module):
    
    def __init__(self, feat_dims:list[int], fusion_dim:int):

        """
        Softmax ê¸°ë°˜ ëª¨ë‹¬ ê°€ì¤‘í•©: ê° ëª¨ë‹¬ì— ì¤‘ìš”ë„ í• ë‹¹ (sum_i=1)

        Args:
            feat_dims (list[int]): ê° ëª¨ë‹¬ì˜ ì°¨ì›
            fusion_dim (int): ìµœì¢… ì°¨ì›
        """

        super().__init__()
        self.gate = nn.Sequential(
            nn.Linear(sum(feat_dims), len(feat_dims)),
            nn.Softmax(dim=-1)
        )
        max_dim = max(feat_dims)
        self.fusion = nn.Linear(max_dim, fusion_dim)
    
    def forward(self, feat_list: list[torch.Tensor]) -> torch.Tensor:
        if not feat_list:
            raise ValueError("No features to fuse")
        concat = torch.cat(feat_list, dim=1)
        weights = self.gate(concat)  # (B, num_modals)
        weighted = sum(weights[:, i].unsqueeze(-1) * feat_list[i] for i in range(len(feat_list)))
        return self.fusion(weighted)


class CrossModalAttention(nn.Module):
    
    def __init__(self, feat_dims:list[int], fusion_dim:int, total_dim:int|None=None, num_heads=8, act_fn=nn.GELU):

        """
        ëª¨ë‹¬ ê°„ Self-Attention: ê° ëª¨ë‹¬ì´ ì„œë¡œë¥¼ ì°¸ê³  (Transformer ìŠ¤íƒ€ì¼)

        Args:
            feat_dims (list[int]): ê° ëª¨ë‹¬ì˜ ì°¨ì›
            fusion_dim (int): ìµœì¢… ì°¨ì›
            total_dim (int): ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì„ë² ë”© ì°¨ì›ì„ ì „ë¶€ í•©ì¹œ ê°’
            num_heads (int): Multi-head Attentionì˜ í—¤ë“œ ìˆ˜
        """

        super().__init__()
        self.mha = None
        self.feat_dims = feat_dims
        self.fusion_dim = fusion_dim
        self.num_heads = num_heads
        self.total_dim = total_dim
        
        if total_dim is not None:
            self.mha = nn.MultiheadAttention(
                embed_dim=total_dim//len(feat_dims),  # per modality dim
                num_heads=num_heads,
                batch_first=True
            )
        self.proj = nn.Linear(total_dim//len(feat_dims), fusion_dim)
    
    def forward(self, feat_list: list[torch.Tensor]) -> torch.Tensor:
        if not feat_list:
            raise ValueError("No features to fuse")
        if self.mha is None:
            self.mha = nn.MultiheadAttention(
                embed_dim=self.total_dim//len(self.feat_dims),  # per modality dim
                num_heads=self.num_heads,
                batch_first=True
            )

        # ê° ëª¨ë‹¬ì„ sequenceë¡œ ì·¨ê¸‰
        feats = torch.stack(feat_list, dim=1)  # (B, num_modals, D)
        (attn_out, _) = self.mha(feats, feats, feats)
        return self.proj(attn_out.mean(dim=1))
    

class HypernetFusion(nn.Module):
    def __init__(self, feat_dims, fusion_dim):

        """
        Args: 
            feat_dims (list[int]): ê° ëª¨ë‹¬ì˜ ì°¨ì›
            fusion_dim (int): ìµœì¢… ì°¨ì›
        """

        super().__init__()
        self.hypernet = nn.Sequential(
            nn.Linear(sum(feat_dims), 128),
            nn.ReLU(),
            nn.Linear(128, sum(feat_dims) * fusion_dim),
            nn.Unflatten(-1, (sum(feat_dims), fusion_dim))
        )
        self.fusion = nn.Linear(sum(feat_dims), fusion_dim)
    
    def forward(self, feat_list: list[torch.Tensor]) -> torch.Tensor:
        if not feat_list:
            raise ValueError("No features to fuse")
        concat = torch.cat(feat_list, dim=1)
        weights = self.hypernet(concat)  # ë™ì  ê°€ì¤‘ì¹˜ ìƒì„±
        weighted_feats = concat.unsqueeze(-1) * weights
        return self.fusion(weighted_feats.mean(-1).sum(1))

import torch
import torch.nn as nn
import torch.nn.functional as F


class ModalMoE(nn.Module):
    def __init__(
        self,
        feat_dims,
        fusion_dim,
        num_experts=4,
        top_k=2,
        act_fn=nn.GELU,
    ):
        """
        Proper MoE with shared input & top-k routing

        Args:
            feat_dims (list[int]): modality feature dims
            fusion_dim (int): hidden dim
            num_experts (int): number of experts
            top_k (int): top-k routing
        """
        super().__init__()

        self.top_k = top_k
        self.num_experts = num_experts
        
        # modality fusion
        self.shared_proj = nn.Sequential(
            nn.Linear(sum(feat_dims), fusion_dim),
            act_fn(),
        )

        #  gate (router)
        self.gate = nn.Linear(fusion_dim, num_experts)

        #  experts (same input dim!)
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(fusion_dim, fusion_dim),
                act_fn(),
            )
            for _ in range(num_experts)
        ])

    def forward(self, feat_list):
        """
        Args:
            feat_list: list of modality tensors [(B, d_i)]
        Returns:
            (B, fusion_dim)
        """
        B = feat_list[0].size(0)

        # ğŸ”¹ shared input
        x = torch.cat(feat_list, dim=1)
        h = self.shared_proj(x)  # (B, D)

        # ğŸ”¹ gating
        gate_logits = self.gate(h)          # (B, E)
        gate_probs = F.softmax(gate_logits, dim=-1)

        topk_probs, topk_idx = gate_probs.topk(self.top_k, dim=-1)  # (B, k)

        # ğŸ”¹ MoE output
        out = torch.zeros_like(h)

        # expert-wise batch routing (vectorized)
        for e in range(self.num_experts):
            mask = (topk_idx == e)          # (B, k)
            if not mask.any():
                continue

            weights = (topk_probs * mask).sum(dim=1)  # (B,)
            selected = weights > 0

            out[selected] += (
                weights[selected].unsqueeze(1)
                * self.experts[e](h[selected])
            )

        return out



class SigmoidModalFusion(nn.Module):
    def __init__(self, feat_dims, fusion_dim):

        """
        Sigmoidí™•ë¥ ë¡œ ê°€ì¤‘í•©

        Args:
            feat_dims (list[int]): ê° ëª¨ë‹¬ì˜ ì°¨ì›
            fusion_dim (int): ìµœì¢… ì°¨ì›
        """

        super().__init__()
        self.num_modals = len(feat_dims)
        self.gate = nn.Sequential(
            nn.Linear(sum(feat_dims), 64),
            nn.ReLU(),
            nn.Linear(64, self.num_modals),
            nn.Sigmoid()  # [0,1] ê°€ì¤‘ì¹˜
        )
        max_dim = max(feat_dims)
        self.fusion = nn.Linear(max_dim, fusion_dim)
    
    def forward(self, feat_list):
        concat = torch.cat(feat_list, dim=1)  # (B, total_dim)
        gates = self.gate(concat)             # (B, num_modals)
        
        weighted = sum(gates[:, i].unsqueeze(-1) * feat_list[i] 
                      for i in range(self.num_modals))
        
        return self.fusion(weighted)
    
if __name__ == "__main__":
    fusion = ModalMoE()